{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression...\n",
      "Logistic Regression Accuracy: 0.9524\n",
      "Training Random Forest...\n",
      "Random Forest Accuracy: 1.0000\n",
      "Training SVM...\n",
      "SVM Accuracy: 0.9048\n",
      "Training Gradient Boosting...\n",
      "Gradient Boosting Accuracy: 1.0000\n",
      "Training KNN...\n",
      "KNN Accuracy: 0.9524\n",
      "Training XGBoost...\n",
      "XGBoost Accuracy: 1.0000\n",
      "Best Model: Random Forest with Accuracy: 1.0000\n",
      "Best model and scalers have been saved to pickle files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saiha\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [23:47:14] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "\n",
    "# Try to import XGBoost (optional)\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    xgb_installed = True\n",
    "except ImportError:\n",
    "    xgb_installed = False\n",
    "    print(\"XGBoost not installed. Skipping XGBoost model.\")\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv(r'Autism_Adolescent_Preprocessed.csv')\n",
    "\n",
    "# Drop missing values\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Extract features and target\n",
    "data_raw = data['Class']\n",
    "features_raw = data[['age', 'gender', 'ethnicity', 'jundice', 'autism', 'relation',\n",
    "                     'contry_of_res', 'A1_Score', 'A2_Score', 'A3_Score', 'A4_Score',\n",
    "                     'A5_Score', 'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score', 'result']]\n",
    "\n",
    "# Apply both MinMaxScaler and StandardScaler\n",
    "minmax_scaler = MinMaxScaler()\n",
    "standard_scaler = StandardScaler()\n",
    "\n",
    "num_features = ['age', 'result']\n",
    "features_transformed = pd.DataFrame(data=features_raw)\n",
    "\n",
    "# Apply MinMaxScaler\n",
    "features_transformed[num_features] = minmax_scaler.fit_transform(features_raw[num_features])\n",
    "\n",
    "# Apply StandardScaler\n",
    "features_transformed[num_features] = standard_scaler.fit_transform(features_transformed[num_features])\n",
    "\n",
    "# One-Hot Encoding\n",
    "features_final = pd.get_dummies(features_transformed)\n",
    "\n",
    "# Encode target variable\n",
    "data_classes = data_raw.apply(lambda x: 1 if x == 'YES' else 0)\n",
    "\n",
    "# Split data\n",
    "np.random.seed(123)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_final, data_classes, test_size=0.2, random_state=1)\n",
    "\n",
    "# Define classification models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=200, random_state=1),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=1),\n",
    "    \"SVM\": SVC(kernel='linear', probability=True, random_state=1),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100, random_state=1),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5)\n",
    "}\n",
    "\n",
    "if xgb_installed:\n",
    "    models[\"XGBoost\"] = XGBClassifier(n_estimators=100, random_state=1, use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Train and evaluate models\n",
    "best_model = None\n",
    "best_accuracy = 0.0\n",
    "best_model_name = \"\"\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{name} Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_model = model\n",
    "        best_model_name = name\n",
    "\n",
    "# Save the best model\n",
    "if best_model:\n",
    "    with open('best_adolescents_model.pkl', 'wb') as f:\n",
    "        pickle.dump(best_model, f)\n",
    "\n",
    "# Save the scalers\n",
    "with open('minmax_scaler(adolescents).pkl', 'wb') as f:\n",
    "    pickle.dump(minmax_scaler, f)\n",
    "\n",
    "with open('standard_scaler(adolescents).pkl', 'wb') as f:\n",
    "    pickle.dump(standard_scaler, f)\n",
    "\n",
    "print(f\"Best Model: {best_model_name} with Accuracy: {best_accuracy:.4f}\")\n",
    "print(\"Best model and scalers have been saved to pickle files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\punna\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\punna\\AppData\\Roaming\\Python\\Python312\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\punna\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\punna\\AppData\\Roaming\\Python\\Python312\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\punna\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\punna\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\punna\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\punna\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\punna\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\punna\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\punna\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\punna\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\punna\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\punna\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\punna\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\punna\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\punna\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\punna\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\punna\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\punna\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\punna\\AppData\\Local\\Temp\\ipykernel_25296\\2592298.py\", line 2, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\punna\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\__init__.py\", line 62, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"C:\\Users\\punna\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"C:\\Users\\punna\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"C:\\Users\\punna\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\arrow\\__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"C:\\Users\\punna\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\arrow\\array.py\", line 50, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"C:\\Users\\punna\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\ops\\__init__.py\", line 8, in <module>\n",
      "    from pandas.core.ops.array_ops import (\n",
      "  File \"C:\\Users\\punna\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\ops\\array_ops.py\", line 56, in <module>\n",
      "    from pandas.core.computation import expressions\n",
      "  File \"C:\\Users\\punna\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\computation\\expressions.py\", line 21, in <module>\n",
      "    from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "  File \"C:\\Users\\punna\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\computation\\check.py\", line 5, in <module>\n",
      "    ne = import_optional_dependency(\"numexpr\", errors=\"warn\")\n",
      "  File \"C:\\Users\\punna\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\compat\\_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"c:\\Users\\punna\\anaconda3\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"c:\\Users\\punna\\anaconda3\\Lib\\site-packages\\numexpr\\__init__.py\", line 24, in <module>\n",
      "    from numexpr.interpreter import MAX_THREADS, use_vml, __BLOCK_SIZE1__\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\punna\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\punna\\AppData\\Roaming\\Python\\Python312\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\punna\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\punna\\AppData\\Roaming\\Python\\Python312\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\punna\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\punna\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\punna\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\punna\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\punna\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\punna\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\punna\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\punna\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\punna\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\punna\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\punna\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\punna\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\punna\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\punna\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\punna\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\punna\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\punna\\AppData\\Local\\Temp\\ipykernel_25296\\2592298.py\", line 2, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\punna\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\__init__.py\", line 62, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"C:\\Users\\punna\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"C:\\Users\\punna\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"C:\\Users\\punna\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\arrow\\__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"C:\\Users\\punna\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\arrow\\array.py\", line 64, in <module>\n",
      "    from pandas.core.arrays.masked import BaseMaskedArray\n",
      "  File \"C:\\Users\\punna\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\masked.py\", line 60, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"C:\\Users\\punna\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\nanops.py\", line 52, in <module>\n",
      "    bn = import_optional_dependency(\"bottleneck\", errors=\"warn\")\n",
      "  File \"C:\\Users\\punna\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\compat\\_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"c:\\Users\\punna\\anaconda3\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"c:\\Users\\punna\\anaconda3\\Lib\\site-packages\\bottleneck\\__init__.py\", line 7, in <module>\n",
      "    from .move import (move_argmax, move_argmin, move_max, move_mean, move_median,\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.2.3 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\core\\_multiarray_umath.py:44\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr_name)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m     46\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.2.3 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model predicts that the individual has ASD.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Load the trained model from the pickle file\n",
    "with open(r'best_adolescents_model.pkl', 'rb') as f:\n",
    "    best_model = pickle.load(f)\n",
    "\n",
    "# Load the scalers used for preprocessing\n",
    "with open(r'minmax_scaler(adolescents).pkl', 'rb') as f:\n",
    "    minmax_scaler = pickle.load(f)\n",
    "\n",
    "with open(r'standard_scaler(adolescents).pkl', 'rb') as f:\n",
    "    standard_scaler = pickle.load(f)\n",
    "\n",
    "# Load the Autism_Adolescent_Data.xlsx file to get the unique values for string labels\n",
    "data = pd.read_csv(r'Autism_Adolescent_Preprocessed.csv')\n",
    "\n",
    "# Get unique values for categorical features\n",
    "unique_genders = data['gender'].unique()\n",
    "unique_ethnicities = data['ethnicity'].unique()\n",
    "unique_jundice = data['jundice'].unique()\n",
    "unique_austim = data['autism'].unique()\n",
    "unique_countries = data['contry_of_res'].unique()\n",
    "unique_relations = data['relation'].unique()\n",
    "\n",
    "# Define the feature columns\n",
    "feature_columns = ['age', 'gender', 'ethnicity', 'jundice', 'autism', 'contry_of_res', 'result',\n",
    "                   'relation', 'A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', 'A6_Score',\n",
    "                   'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score']\n",
    "\n",
    "# Preprocess the training data to get the reference columns\n",
    "data.dropna(inplace=True)\n",
    "data_raw = data['Class']\n",
    "features_raw = data[['age', 'gender', 'ethnicity', 'jundice', 'autism', 'relation',\n",
    "                     'contry_of_res', 'A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score',\n",
    "                     'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score', 'result']]\n",
    "\n",
    "features_transform = pd.DataFrame(data=features_raw)\n",
    "\n",
    "# Apply both MinMaxScaler and StandardScaler\n",
    "features_transform[['age', 'result']] = minmax_scaler.transform(features_raw[['age', 'result']])\n",
    "features_transform[['age', 'result']] = standard_scaler.transform(features_transform[['age', 'result']])\n",
    "\n",
    "features_final = pd.get_dummies(features_transform)\n",
    "reference_columns = features_final.columns\n",
    "\n",
    "# Function to preprocess user input\n",
    "def preprocess_input(user_input):\n",
    "    # Convert user input to DataFrame\n",
    "    input_df = pd.DataFrame([user_input], columns=feature_columns)\n",
    "    \n",
    "    # Apply the same preprocessing steps as in the training script\n",
    "    input_df[['age', 'result']] = minmax_scaler.transform(input_df[['age', 'result']])\n",
    "    input_df[['age', 'result']] = standard_scaler.transform(input_df[['age', 'result']])\n",
    "    \n",
    "    input_df = pd.get_dummies(input_df)\n",
    "    \n",
    "    # Ensure all columns are present\n",
    "    for col in reference_columns:\n",
    "        if col not in input_df.columns:\n",
    "            input_df[col] = 0\n",
    "    \n",
    "    # Reorder columns to match the training data\n",
    "    input_df = input_df[reference_columns]\n",
    "    \n",
    "    return input_df\n",
    "\n",
    "# Function to get user input and make prediction\n",
    "def get_user_input_and_predict():\n",
    "    # Get user input\n",
    "    user_input = {\n",
    "        'age': float(input(\"Enter age (e.g., 12-16): \")),\n",
    "        'gender': input(f\"Enter gender ({'/'.join(unique_genders)}): \").strip().upper(),\n",
    "        'ethnicity': input(f\"Enter ethnicity ({'/'.join(unique_ethnicities)}): \").strip(),\n",
    "        'jundice': input(f\"Had jaundice ({'/'.join(unique_jundice)}): \").strip().lower(),\n",
    "        'autism': input(f\"Family member with autism ({'/'.join(unique_austim)}): \").strip().lower(),\n",
    "        'contry_of_res': input(f\"Enter country of residence ({'/'.join(unique_countries)}): \").strip(),\n",
    "        'result': float(input(\"Enter result (e.g., 10.0): \")),\n",
    "        'relation': input(f\"Enter relation ({'/'.join(unique_relations)}): \").strip(),\n",
    "        'A1_Score': get_int_input(\"Enter A1_Score (0 or 1): \"),\n",
    "        'A2_Score': get_int_input(\"Enter A2_Score (0 or 1): \"),\n",
    "        'A3_Score': get_int_input(\"Enter A3_Score (0 or 1): \"),\n",
    "        'A4_Score': get_int_input(\"Enter A4_Score (0 or 1): \"),\n",
    "        'A5_Score': get_int_input(\"Enter A5_Score (0 or 1): \"),\n",
    "        'A6_Score': get_int_input(\"Enter A6_Score (0 or 1): \"),\n",
    "        'A7_Score': get_int_input(\"Enter A7_Score (0 or 1): \"),\n",
    "        'A8_Score': get_int_input(\"Enter A8_Score (0 or 1): \"),\n",
    "        'A9_Score': get_int_input(\"Enter A9_Score (0 or 1): \"),\n",
    "        'A10_Score': get_int_input(\"Enter A10_Score (0 or 1): \")\n",
    "    }\n",
    "    \n",
    "    # Preprocess the input\n",
    "    input_df = preprocess_input(user_input)\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = best_model.predict(input_df)\n",
    "    \n",
    "    # Print the prediction\n",
    "    if prediction[0] == 1:\n",
    "        print(\"The model predicts that the individual has ASD.\")\n",
    "    else:\n",
    "        print(\"The model predicts that the individual does not have ASD.\")\n",
    "\n",
    "# Helper function to get integer input\n",
    "def get_int_input(prompt):\n",
    "    while True:\n",
    "        try:\n",
    "            value = int(input(prompt))\n",
    "            return value\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Please enter an integer value.\")\n",
    "\n",
    "# Call the function to get user input and make prediction\n",
    "get_user_input_and_predict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
