{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.9828\n",
      "Model and scaler have been saved to pickle files.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_excel('Autism_Child_Data1.xlsx')\n",
    "\n",
    "# Preprocess the data\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Convert the Pandas dataframes into numpy arrays that can be used by scikit_learn\n",
    "data_raw = data['Class/ASD']\n",
    "features_raw = data[['age', 'gender', 'ethnicity', 'jundice', 'austim', 'contry_of_res', 'result',\n",
    "                     'relation', 'A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', 'A6_Score', 'A7_Score', 'A8_Score',\n",
    "                     'A9_Score', 'A10_Score']]\n",
    "\n",
    "# Data Preprocessing: using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "num = ['age', 'result']\n",
    "features_minmax_transform = pd.DataFrame(data=features_raw)\n",
    "features_minmax_transform[num] = scaler.fit_transform(features_raw[num])\n",
    "\n",
    "# One-Hot Encoding on features_minmax_transform\n",
    "features_final = pd.get_dummies(features_minmax_transform)\n",
    "\n",
    "# Encode all classes data to numerical values\n",
    "data_classes = data_raw.apply(lambda x: 1 if x == 'YES' else 0)\n",
    "\n",
    "# Shuffle and Split the data\n",
    "np.random.seed(123)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_final, data_classes, test_size=0.2, random_state=1)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "lr_model = LogisticRegression(max_iter=200, random_state=1)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred_lr)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Save the trained model to a pickle file\n",
    "with open('Child_model.pkl', 'wb') as f:\n",
    "    pickle.dump(lr_model, f)\n",
    "\n",
    "# Save the scaler to a pickle file\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "print(\"Model and scaler have been saved to pickle files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of      A1_Score  A2_Score  A3_Score  A4_Score  A5_Score  A6_Score  A7_Score  \\\n",
      "0           1         1         0         0         1         1         0   \n",
      "1           1         1         0         0         1         1         0   \n",
      "2           1         1         0         0         0         1         1   \n",
      "3           0         1         0         0         1         1         0   \n",
      "4           1         1         1         1         1         1         1   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "287         1         1         1         1         1         1         1   \n",
      "288         1         0         0         0         1         0         1   \n",
      "289         1         0         1         1         1         1         1   \n",
      "290         1         1         1         0         1         1         1   \n",
      "291         0         0         1         0         1         0         1   \n",
      "\n",
      "     A8_Score  A9_Score  A10_Score  ...  gender       ethnicity jundice  \\\n",
      "0           1         0          0  ...       m          Others      no   \n",
      "1           1         0          0  ...       m  Middle Eastern      no   \n",
      "2           1         0          0  ...       m          Others      no   \n",
      "3           0         0          1  ...       f          Others     yes   \n",
      "4           1         1          1  ...       m          Others     yes   \n",
      "..        ...       ...        ...  ...     ...             ...     ...   \n",
      "287         1         1          1  ...       f  White-European     yes   \n",
      "288         0         0          1  ...       f  White-European     yes   \n",
      "289         0         0          1  ...       m          Latino      no   \n",
      "290         1         1          1  ...       m     South Asian      no   \n",
      "291         0         0          0  ...       f     South Asian      no   \n",
      "\n",
      "    austim contry_of_res used_app_before result    age_desc relation Class/ASD  \n",
      "0       no        Jordan              no      5  4-11 years   Parent        NO  \n",
      "1       no        Jordan              no      5  4-11 years   Parent        NO  \n",
      "2       no        Jordan             yes      5  4-11 years   Others        NO  \n",
      "3       no        Jordan              no      4  4-11 years   Others        NO  \n",
      "4       no           USA              no     10  4-11 years   Parent       YES  \n",
      "..     ...           ...             ...    ...         ...      ...       ...  \n",
      "287    yes            UK              no     10  4-11 years   Parent       YES  \n",
      "288    yes     Australia              no      4  4-11 years   Parent        NO  \n",
      "289     no        Brazil              no      7  4-11 years   Parent       YES  \n",
      "290     no         India              no      9  4-11 years   Parent       YES  \n",
      "291     no         India              no      3  4-11 years   Parent        NO  \n",
      "\n",
      "[292 rows x 21 columns]>\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('Preprocessed_Autism_Data_child.csv')\n",
    "print(data.head)\n",
    "# Get unique values for categorical features\n",
    "unique_genders = data['gender'].unique()\n",
    "unique_ethnicities = data['ethnicity'].unique()\n",
    "unique_jundice = data['jundice'].unique()\n",
    "unique_austim = data['austim'].unique()\n",
    "unique_countries = data['contry_of_res'].unique()\n",
    "unique_relations = data['relation'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Others' 'Middle Eastern' 'White-European' 'Black' 'South Asian' 'Asian'\n",
      " 'Pasifika' 'Hispanic' 'Turkish' 'Latino']\n",
      "\n",
      "['no' 'yes']\n",
      "\n",
      "['Jordan' 'USA' 'Egypt' 'UK' 'Bahrain' 'Austria' 'Kuwait' 'UAE' 'Europe'\n",
      " 'Malta' 'Bulgaria' 'South Africa' 'India' 'Afghanistan' 'Georgia'\n",
      " 'New Zealand' 'Syria' 'Iraq' 'Australia' 'Saudi Arabia' 'Armenia'\n",
      " 'Turkey' 'Pakistan' 'Canada' 'Oman' 'Brazil' 'South Korea' 'Costa Rica'\n",
      " 'Sweden' 'Philippines' 'Malaysia' 'Argentina' 'Japan' 'Bangladesh'\n",
      " 'Qatar' 'Ireland' 'Romania' 'Netherlands' 'Lebanon' 'Germany' 'Latvia'\n",
      " 'Russia' 'Italy' 'China' 'Nigeria' 'US Outlying Islands' 'Nepal' 'Mexico'\n",
      " 'Isle of Man' 'Libya' 'Ghana' 'Bhutan']\n",
      "\n",
      "['Parent' 'Others' 'Self' 'Relative' 'Healthcare Professional']\n",
      "\n",
      "['no' 'yes']\n"
     ]
    }
   ],
   "source": [
    "print(unique_ethnicities,unique_jundice,unique_countries,unique_relations,unique_austim,sep=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing complete. File saved as 'Preprocessed_Autism_Data_child.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_excel(r\"Autism_Child_Data1.xlsx\")\n",
    "\n",
    "# Handle missing or unknown values\n",
    "df.replace(\"?\", \"Others\", inplace=True)\n",
    "\n",
    "# Standardize text format: Trim spaces, remove extra quotes, and use title case\n",
    "df['ethnicity'] = df['ethnicity'].astype(str).str.strip().str.title()\n",
    "df['contry_of_res'] = df['contry_of_res'].astype(str).str.strip().str.title()\n",
    "df['relation'] = df['relation'].astype(str).str.strip().str.title()\n",
    "\n",
    "# Dictionary for country name corrections\n",
    "country_corrections = {\n",
    "    'United States': 'USA',\n",
    "    'United Kingdom': 'UK',\n",
    "    'United Arab Emirates': 'UAE',\n",
    "    'Viet Nam': 'Vietnam',\n",
    "    'U.S. Outlying Islands': 'US Outlying Islands',\n",
    "    'Isle Of Man': 'Isle of Man'\n",
    "}\n",
    "\n",
    "# Dictionary for ethnicity corrections\n",
    "ethnicity_corrections = {\n",
    "    'Middle Eastern ': 'Middle Eastern',\n",
    "    'South Asian': 'South Asian'\n",
    "}\n",
    "\n",
    "# Dictionary for relation corrections\n",
    "relation_corrections = {\n",
    "    'Self': 'Self',\n",
    "    'self': 'Self',\n",
    "    'Health Care Professional': 'Healthcare Professional'\n",
    "}\n",
    "\n",
    "# Apply spelling corrections\n",
    "df['contry_of_res'] = df['contry_of_res'].replace(country_corrections)\n",
    "df['ethnicity'] = df['ethnicity'].replace(ethnicity_corrections)\n",
    "df['relation'] = df['relation'].replace(relation_corrections)\n",
    "\n",
    "# Save the cleaned data to a new CSV file\n",
    "df.to_csv(r\"Preprocessed_Autism_Data_child.csv\", index=False)\n",
    "\n",
    "print(\"Preprocessing complete. File saved as 'Preprocessed_Autism_Data_child.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 1.0000\n",
      "Model and scalers have been saved to pickle files.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('Preprocessed_Autism_Data_child.csv')\n",
    "\n",
    "# Preprocess the data\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Convert the target column to binary (1 for 'YES', 0 otherwise)\n",
    "data_classes = data['Class/ASD'].apply(lambda x: 1 if x == 'YES' else 0)\n",
    "\n",
    "# Define features\n",
    "features_raw = data[['age', 'gender', 'ethnicity', 'jundice', 'austim', \n",
    "                     'contry_of_res', 'result', 'relation', 'A1_Score', \n",
    "                     'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', \n",
    "                     'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score']].copy()  # ✅ Copy added\n",
    "\n",
    "# Define numerical columns\n",
    "num_columns = ['age', 'result']\n",
    "\n",
    "# Initialize scalers\n",
    "minmax_scaler = MinMaxScaler()\n",
    "standard_scaler = StandardScaler()\n",
    "\n",
    "# Apply MinMaxScaler\n",
    "features_minmax = features_raw.copy()  # ✅ Copy added\n",
    "features_minmax[num_columns] = minmax_scaler.fit_transform(features_minmax[num_columns])\n",
    "\n",
    "# Apply StandardScaler\n",
    "features_standard = features_raw.copy()  # ✅ Copy added\n",
    "features_standard[num_columns] = standard_scaler.fit_transform(features_standard[num_columns])\n",
    "\n",
    "# One-Hot Encoding\n",
    "features_final = pd.get_dummies(features_standard)\n",
    "\n",
    "# Shuffle and split the data\n",
    "np.random.seed(123)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_final, data_classes, test_size=0.2, random_state=1)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "lr_model = LogisticRegression(max_iter=200, random_state=1)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred_lr)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Save the trained model\n",
    "with open('Child_model.pkl', 'wb') as f:\n",
    "    pickle.dump(lr_model, f)\n",
    "\n",
    "# Save the MinMax scaler\n",
    "with open('minmax_scaler(Childs).pkl', 'wb') as f:\n",
    "    pickle.dump(minmax_scaler, f)\n",
    "\n",
    "# Save the Standard scaler\n",
    "with open('standard_scaler(Childs).pkl', 'wb') as f:\n",
    "    pickle.dump(standard_scaler, f)\n",
    "\n",
    "print(\"Model and scalers have been saved to pickle files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model predicts that the individual does not have ASD.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Load the trained Logistic Regression model from the pickle file\n",
    "with open('Child_model.pkl', 'rb') as f:\n",
    "    lr_model = pickle.load(f)\n",
    "\n",
    "# Load the MinMaxScaler\n",
    "with open('minmax_scaler(Childs).pkl', 'rb') as f:\n",
    "    minmax_scaler = pickle.load(f)\n",
    "\n",
    "# Load the StandardScaler\n",
    "with open('standard_scaler(Childs).pkl', 'rb') as f:\n",
    "    standard_scaler = pickle.load(f)\n",
    "\n",
    "# Load the dataset to get unique values for categorical features\n",
    "data = pd.read_csv('Preprocessed_Autism_Data_child.csv')\n",
    "\n",
    "# Get unique values for categorical features\n",
    "unique_genders = data['gender'].unique()\n",
    "unique_ethnicities = data['ethnicity'].unique()\n",
    "unique_jundice = data['jundice'].unique()\n",
    "unique_austim = data['austim'].unique()\n",
    "unique_countries = data['contry_of_res'].unique()\n",
    "unique_relations = data['relation'].unique()\n",
    "\n",
    "# Define feature columns\n",
    "feature_columns = ['age', 'gender', 'ethnicity', 'jundice', 'austim', 'contry_of_res', 'result',\n",
    "                   'relation', 'A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', 'A6_Score',\n",
    "                   'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score']\n",
    "\n",
    "# Preprocess the training data to get reference columns\n",
    "data.dropna(inplace=True)\n",
    "features_raw = data[feature_columns].copy()\n",
    "features_transformed = features_raw.copy()\n",
    "\n",
    "# Apply both scalers\n",
    "features_transformed[['age', 'result']] = minmax_scaler.transform(features_raw[['age', 'result']])\n",
    "features_transformed[['age', 'result']] = standard_scaler.transform(features_transformed[['age', 'result']])\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "features_final = pd.get_dummies(features_transformed)\n",
    "\n",
    "# Store reference columns\n",
    "reference_columns = features_final.columns\n",
    "\n",
    "# Function to preprocess user input\n",
    "def preprocess_input(user_input):\n",
    "    # Convert user input to DataFrame\n",
    "    input_df = pd.DataFrame([user_input], columns=feature_columns)\n",
    "\n",
    "    # Apply both scalers\n",
    "    input_df[['age', 'result']] = minmax_scaler.transform(input_df[['age', 'result']])\n",
    "    input_df[['age', 'result']] = standard_scaler.transform(input_df[['age', 'result']])\n",
    "\n",
    "    # One-hot encode categorical variables\n",
    "    input_df = pd.get_dummies(input_df)\n",
    "\n",
    "    # Ensure all columns are present\n",
    "    for col in reference_columns:\n",
    "        if col not in input_df.columns:\n",
    "            input_df[col] = 0\n",
    "\n",
    "    # Reorder columns to match training data\n",
    "    input_df = input_df[reference_columns]\n",
    "\n",
    "    return input_df\n",
    "\n",
    "# Function to get user input and make prediction\n",
    "def get_user_input_and_predict():\n",
    "    # Get user input\n",
    "    user_input = {\n",
    "        'age': float(input(\"Enter age (e.g., 4-11): \")),\n",
    "        'gender': input(f\"Enter gender ({'/'.join(unique_genders)}): \").strip().upper(),\n",
    "        'ethnicity': input(f\"Enter ethnicity ({'/'.join(unique_ethnicities)}): \").strip(),\n",
    "        'jundice': input(f\"Had jaundice ({'/'.join(unique_jundice)}): \").strip().lower(),\n",
    "        'austim': input(f\"Family member with autism ({'/'.join(unique_austim)}): \").strip().lower(),\n",
    "        'contry_of_res': input(f\"Enter country of residence ({'/'.join(unique_countries)}): \").strip(),\n",
    "        'result': float(input(\"Enter result (e.g., 10.0): \")),\n",
    "        'relation': input(f\"Enter relation ({'/'.join(unique_relations)}): \").strip(),\n",
    "        'A1_Score': int(input(\"Enter A1_Score (0 or 1): \")),\n",
    "        'A2_Score': int(input(\"Enter A2_Score (0 or 1): \")),\n",
    "        'A3_Score': int(input(\"Enter A3_Score (0 or 1): \")),\n",
    "        'A4_Score': int(input(\"Enter A4_Score (0 or 1): \")),\n",
    "        'A5_Score': int(input(\"Enter A5_Score (0 or 1): \")),\n",
    "        'A6_Score': int(input(\"Enter A6_Score (0 or 1): \")),\n",
    "        'A7_Score': int(input(\"Enter A7_Score (0 or 1): \")),\n",
    "        'A8_Score': int(input(\"Enter A8_Score (0 or 1): \")),\n",
    "        'A9_Score': int(input(\"Enter A9_Score (0 or 1): \")),\n",
    "        'A10_Score': int(input(\"Enter A10_Score (0 or 1): \"))\n",
    "    }\n",
    "\n",
    "    # Preprocess the input\n",
    "    input_df = preprocess_input(user_input)\n",
    "\n",
    "    # Make prediction\n",
    "    prediction = lr_model.predict(input_df)\n",
    "\n",
    "    # Print the prediction\n",
    "    if prediction[0] == 1:\n",
    "        print(\"The model predicts that the individual has ASD.\")\n",
    "    else:\n",
    "        print(\"The model predicts that the individual does not have ASD.\")\n",
    "\n",
    "# Call the function to get user input and make prediction\n",
    "get_user_input_and_predict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-27 00:11:12.123 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run c:\\Users\\saiha\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-02-27 00:11:12.127 Session state does not function when running a script without `streamlit run`\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Load the trained Logistic Regression model\n",
    "with open('Child_model.pkl', 'rb') as f:\n",
    "    lr_model = pickle.load(f)\n",
    "\n",
    "# Load the MinMaxScaler\n",
    "with open('minmax_scaler(Childs).pkl', 'rb') as f:\n",
    "    minmax_scaler = pickle.load(f)\n",
    "\n",
    "# Load the StandardScaler\n",
    "with open('standard_scaler(Childs).pkl', 'rb') as f:\n",
    "    standard_scaler = pickle.load(f)\n",
    "\n",
    "# Load dataset to get unique values for categorical features\n",
    "data = pd.read_excel(\"Autism_Child_Data1.xlsx\")\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Extract unique values for categorical inputs\n",
    "unique_genders = data['gender'].unique()\n",
    "unique_ethnicities = data['ethnicity'].unique()\n",
    "unique_jundice = data['jundice'].unique()\n",
    "unique_austim = data['austim'].unique()\n",
    "unique_countries = data['contry_of_res'].unique()\n",
    "unique_relations = data['relation'].unique()\n",
    "\n",
    "# Define feature columns\n",
    "feature_columns = ['age', 'gender', 'ethnicity', 'jundice', 'austim', 'contry_of_res', 'result',\n",
    "                   'relation', 'A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', 'A6_Score',\n",
    "                   'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score']\n",
    "\n",
    "# Process training data for reference columns\n",
    "features_raw = data[feature_columns].copy()\n",
    "features_transformed = features_raw.copy()\n",
    "features_transformed[['age', 'result']] = minmax_scaler.transform(features_raw[['age', 'result']])\n",
    "features_transformed[['age', 'result']] = standard_scaler.transform(features_transformed[['age', 'result']])\n",
    "features_final = pd.get_dummies(features_transformed)\n",
    "reference_columns = features_final.columns\n",
    "\n",
    "def preprocess_input(user_input):\n",
    "    input_df = pd.DataFrame([user_input], columns=feature_columns)\n",
    "    input_df[['age', 'result']] = minmax_scaler.transform(input_df[['age', 'result']])\n",
    "    input_df[['age', 'result']] = standard_scaler.transform(input_df[['age', 'result']])\n",
    "    input_df = pd.get_dummies(input_df)\n",
    "    \n",
    "    for col in reference_columns:\n",
    "        if col not in input_df.columns:\n",
    "            input_df[col] = 0\n",
    "    \n",
    "    return input_df[reference_columns]\n",
    "\n",
    "# Streamlit UI\n",
    "st.title(\"Autism Spectrum Disorder (ASD) Prediction\")\n",
    "st.write(\"Fill in the details below to get a prediction.\")\n",
    "\n",
    "age = st.number_input(\"Age\", min_value=1, max_value=100, value=5)\n",
    "gender = st.selectbox(\"Gender\", unique_genders)\n",
    "ethnicity = st.selectbox(\"Ethnicity\", unique_ethnicities)\n",
    "jundice = st.selectbox(\"Had jaundice?\", unique_jundice)\n",
    "austim = st.selectbox(\"Family member with autism?\", unique_austim)\n",
    "country = st.selectbox(\"Country of residence\", unique_countries)\n",
    "result = st.number_input(\"Test Result (e.g., 10.0)\", min_value=0.0, value=10.0)\n",
    "relation = st.selectbox(\"Relation\", unique_relations)\n",
    "\n",
    "# Autism test scores (0 or 1)\n",
    "a1 = st.radio(\"A1 Score\", [0, 1])\n",
    "a2 = st.radio(\"A2 Score\", [0, 1])\n",
    "a3 = st.radio(\"A3 Score\", [0, 1])\n",
    "a4 = st.radio(\"A4 Score\", [0, 1])\n",
    "a5 = st.radio(\"A5 Score\", [0, 1])\n",
    "a6 = st.radio(\"A6 Score\", [0, 1])\n",
    "a7 = st.radio(\"A7 Score\", [0, 1])\n",
    "a8 = st.radio(\"A8 Score\", [0, 1])\n",
    "a9 = st.radio(\"A9 Score\", [0, 1])\n",
    "a10 = st.radio(\"A10 Score\", [0, 1])\n",
    "\n",
    "if st.button(\"Predict ASD Status\"):\n",
    "    user_input = {\n",
    "        'age': age,\n",
    "        'gender': gender,\n",
    "        'ethnicity': ethnicity,\n",
    "        'jundice': jundice,\n",
    "        'austim': austim,\n",
    "        'contry_of_res': country,\n",
    "        'result': result,\n",
    "        'relation': relation,\n",
    "        'A1_Score': a1,\n",
    "        'A2_Score': a2,\n",
    "        'A3_Score': a3,\n",
    "        'A4_Score': a4,\n",
    "        'A5_Score': a5,\n",
    "        'A6_Score': a6,\n",
    "        'A7_Score': a7,\n",
    "        'A8_Score': a8,\n",
    "        'A9_Score': a9,\n",
    "        'A10_Score': a10\n",
    "    }\n",
    "    \n",
    "    input_df = preprocess_input(user_input)\n",
    "    prediction = lr_model.predict(input_df)\n",
    "    result_text = \"The model predicts that the individual has ASD.\" if prediction[0] == 1 else \"The model predicts that the individual does not have ASD.\"\n",
    "    \n",
    "    st.subheader(\"Prediction Result\")\n",
    "    st.write(result_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
